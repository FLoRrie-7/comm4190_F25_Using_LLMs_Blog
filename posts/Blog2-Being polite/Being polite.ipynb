{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0194a544-3523-4667-bbed-b5ea78ffb1ff",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Are you being overly polite to your LLMs?\"\n",
    "description: \"Does politeness actually promote genAI’s performance?\" \n",
    "author: \"Florrie\"\n",
    "date: \"9/10/2025\"\n",
    "categories:\n",
    "  - HCI\n",
    "  - Communication\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b106ac3-3d77-42e8-bb3d-8cdb27e4bccf",
   "metadata": {},
   "source": [
    "                          ![Image](Polite.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5662fe-c625-4103-b277-cdaec1f36663",
   "metadata": {},
   "source": [
    "Politeness is a cornerstone of human interaction. We use courteous language when asking for help because we understand that **politeness strategies**—using \"please\" and \"thank you\"—greatly influence conversational vibes, manage emotions, and ultimately affect the quality of help we receive. This is central to **politeness theory**, which explains how we use language to maintain social harmony. But what about when our conversational partner is a Large Language Model (LLM)? Lacking a human-like emotional faculty (or say a human-like emotion faculty. Trying not to be a human chauvinism here), would an LLM provide a better response just because we’re nice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33e457-623e-4325-bc63-97ef60832ab9",
   "metadata": {},
   "source": [
    "## Why does it matter?\n",
    "\n",
    "This matters because because it also has real-world consequences. Using courteous language is both financially and environmentally costly. LLMs bill and burn energy roughly per token. Basically, **more words → more tokens → more compute → more electricity**. A recent synthesis estimated a typical ChatGPT query consumes about 0.3 Wh of energy. Adding a few polite words might increase that consumption by 5-10%, a significant amount when scaled globally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ef5b9-9bb8-46a9-a739-0ac319738ad2",
   "metadata": {},
   "source": [
    "While designers at Microsoft Copilot suggest polite prompts elicit more cooperative responses, is true in life across models and types of questions? I ran a small experiment using two distinct prompts to see if the answers really differ: a direct deman and an indirect inquiry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f5616-7228-47f9-844b-b87a54b3de6c",
   "metadata": {},
   "source": [
    "\n",
    ">**Prompt 1 (Direct/Demanding)**:\n",
    ">*Do a research and provide a list of must-try restaurant in Philadelphia*\n",
    "\n",
    "\n",
    ">**Prompt 2 (Indirect/Polite)**:\n",
    ">*Would you please do a research, and provide a list of must-try restaurant in Philadelphia for me? Thank you!*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad86c7c-3406-450a-adcd-6660ddb8c8db",
   "metadata": {},
   "source": [
    "## How did the models perform?\n",
    "\n",
    "On *Gemini 2.5 Flash*, the demanding request yielded a comprehensive response, including an introduction to Philly’s food scene, a \"Tip\" section, and a of 10 restaurant recommendations. The courteous inquiry produced a response with a similar structure but a softer, more affiliative tone. Crucially, the polite prompt's main list of 11 restaurants was __more organized__, with categories like “Fine Dining & Special Occasion” and “Trendy & Modern” to provide a little more information. Take a closer look, the descriptions of each restaurant also seem to be __more detailed__ with locations and price references:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa308542-d3f8-45a1-8bb0-4b7d4fb1f9a6",
   "metadata": {},
   "source": [
    ">*With a direct/demanding prompt*\n",
    ">![Image](Gemini1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c1ce6-88f7-45ce-a8d0-6c434c375466",
   "metadata": {},
   "source": [
    ">*With an indirect/polite prompt*\n",
    ">![Image](Gemini2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de899a-e08a-4b75-b922-464e28944eff",
   "metadata": {},
   "source": [
    "And its \"Tip\" section also seemed to be richer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97faa38-46b2-4c23-86a0-83782dc5bf4d",
   "metadata": {},
   "source": [
    ">*With a direct/demanding prompt*\n",
    ">![Image](Gemini3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40c072-71bc-4880-b78f-a9ae1411ef4f",
   "metadata": {},
   "source": [
    ">*With an indirect/polite prompt*\n",
    ">![Image](Gemini4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63008279-1df8-4f2b-80b6-1efbc6e9f6e0",
   "metadata": {},
   "source": [
    "However, the results weren't consistent across different models. GPT 4-o returned nearly identical content for both prompts, just with a friendlier tone in response to the polite query. Meanwhile, Claude 3.5 sonnet does not seem to care at all: It gave out essentially the same content and expressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c30e61-5f83-44f6-a0e7-8a39d2aa7918",
   "metadata": {},
   "source": [
    "## Conclusion from this mini-experiment\n",
    "\n",
    "My conclusion is that while some models may perform slightly better with polite prompts, the improvement is often marginal. A not-validated assumption might be that the linguistic patterns of polite inquiries, which often include more detailed framing (\"...for me?\"), are simply correlated in its training data with more structured, helpful, and detailed human-written examples. The politeness itself may be a confounding variable. AI is not feeling anything and respond under its emotions. It’s still the computational magic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2b1a1-9bdf-4587-8b5c-1d2098d1c4fc",
   "metadata": {},
   "source": [
    "## A Psychology, or HCI perspective, or a business perspective\n",
    "\n",
    "So, why bother being polite? A few months ago, [Sam Altman](https://wccftech.com/saying-thank-you-and-being-polite-to-chatgpt-is-costing-tens-of-millions-but-sam-altman-says-its-money-well-spent/) replied on X to a question about this very issue, saying the electricity cost was, *\"Tens of millions of dollars well spent — you never know.\"* Perhaps the real benefit isn't in the raw output but in shaping the __communicative norms__ around AI. A courteous interaction can lead to a __smoother user experience and a healthier human-AI culture__. I did find the polite exchange more comfortable and was more willing to continue the conversation. For tech companies, this enhanced HCI experience is certainly a __product-win__, making it worth a marginal energy cost. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
