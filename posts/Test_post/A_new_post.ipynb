{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4582f78f-c21f-4b98-addb-5309cdd2a024",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"How would your AI make suggestions that are right specifically for you?\"\n",
    "description: \"What you might not encounter in conversations with a human\" \n",
    "author: \"Florrie\"\n",
    "date: \"9/4/2025\"\n",
    "categories:\n",
    "  - Personalization\n",
    "  - HCI\n",
    "  - Cognitive Sciences\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e953c4b-90da-4660-be47-75e4ce4619e4",
   "metadata": {},
   "source": [
    "## My LLMs sometimes know more about me than I do\n",
    "\n",
    "> It’s the beginning of another beautiful semester — and according to the syllabus of my communication course, we are required to pick a book from a list of seven on the topic of AI to read throughout the academic term.\n",
    "    \n",
    "> Usually, I would let my large language model introduce each book to me to get a snapshot and then make a judgment myself. This time, I decided to take it a step further and treat the interaction as a small communicative experiment. I would ask the LLM to act as a consultant and actively suggest the best options for me.\n",
    "\n",
    "> This should be a reasonable task for an LLM: I've been using this particular model mainly for school and work since 2023, so our interaction history forms a **rich data** of my academic and intellectual interests. Therefore, it should be able to generate tailored suggestions. However,I decided to make my intention clear in the ask, because I don't assume it will automatically take my background into account, which a human would probably do:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c02ad2-beb3-43e2-9dc8-3deb46e9c0a7",
   "metadata": {},
   "source": [
    "![Image](https://commjhub.asc.upenn.edu/hub/user-redirect/lab/tree/comm4190_F25/comm4190_F25_Using_LLMs_Blog/posts/Test_post/LLM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b90f102-262c-4d68-a859-853fc4a4c4f1",
   "metadata": {},
   "source": [
    "> Here, instead of merely paraphrasing the assignment, I included the full text from the syllabus. From a pragmatics perspective, this provides the LLM with **maximum context** for the current exchange (Shhh, not because I was too lazy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a90276-2f3c-409d-ab1a-5d839b85c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "> After 42 seconds, the model returned a long response structured in a very deliberate way:\n",
    "> * An opening comment on the assignment. \n",
    "> * My top 3 picks with rationales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
