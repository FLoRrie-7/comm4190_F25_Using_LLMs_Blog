{
 "cells": [
  {
   "cell_type": "raw",
   "id": "41b99438-77da-4cdb-99d6-a8e9b9acf920",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Personalized and excessively long suggestions from LLMs\"\n",
    "description: \"What you might not encounter in conversations with a human\"\n",
    "author: \"Florrie\"\n",
    "date: \"2025-09-04\"\n",
    "categories:\n",
    "  - Personalization\n",
    "  - HCI\n",
    "  - Cognitive Sciences\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a88d6-580a-4495-bfd1-dc434681655b",
   "metadata": {},
   "source": [
    "![Image](Personalization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e953c4b-90da-4660-be47-75e4ce4619e4",
   "metadata": {},
   "source": [
    "## My LLMs sometimes know more about me than I do\n",
    "\n",
    "It’s the beginning of another beautiful semester — and according to the syllabus of my communication course, we are required to pick a book from a list of seven on the topic of AI to read throughout the academic term.\n",
    "    \n",
    "Usually, I would let my large language model introduce each book to me to get a snapshot and then make a judgment myself. This time, I decided to take it a step further and treat the interaction as a small communicative experiment. I would ask the LLM to act as a consultant and actively suggest the best options for me.\n",
    "\n",
    "This should be a reasonable task for an LLM: I've been using this particular model mainly for school and work since 2023, so our interaction history forms a **rich data** of my academic and intellectual interests. Therefore, it should be able to generate tailored suggestions. However,I decided to make my intention clear in the ask, because I don't assume it will automatically take my background into account, which a human would probably do:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c02ad2-beb3-43e2-9dc8-3deb46e9c0a7",
   "metadata": {},
   "source": [
    "> ![Image](LLM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51309c9-45bd-404d-9aba-b8f874f94c1c",
   "metadata": {},
   "source": [
    "Here, instead of merely paraphrasing the assignment, I included the full text from the syllabus. From a pragmatics perspective, this provides the LLM with **maximum context** for the current exchange (Shhh, not because I was too lazy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45d33f-1e02-47ee-b2a1-402365e69449",
   "metadata": {},
   "source": [
    "After 42 seconds, the model returned a long response structured in a very deliberate way:\n",
    " * An opening comment on the assignment. \n",
    " * His top 3 picks with rationales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d69f6-708b-47d2-8c77-0613d0a293c3",
   "metadata": {},
   "source": [
    "***\n",
    "> ![Image](LLM2.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ecfdbd-0094-4ccf-af29-ebddb5abb84d",
   "metadata": {},
   "source": [
    "  * A parting line, then a short introduction for each book.\n",
    "  * Another parting line, then ideas for how the books could be incorporated into my existing work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f44f2-e39f-4875-a335-900a5421847a",
   "metadata": {},
   "source": [
    "***\n",
    "> ![Image](LLM3.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c26fe2-4e83-4b61-b4a2-b93072b238d1",
   "metadata": {},
   "source": [
    "  * A final parting line, the suggested ranking list\n",
    "  * Tips for the assignment and, finally, a follow-up question to invite more interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb413b5-40d3-4a18-a0e0-551eb88ef5f2",
   "metadata": {},
   "source": [
    "***\n",
    "> ![Image](LLM4.png)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82d445-2e6d-4f51-aefd-1e2d5ed0b77b",
   "metadata": {},
   "source": [
    "The response was comprehensive, seemingly designed to anticipate and address all my potential questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff66e0-cbb3-40ce-bb80-7f086fc8a11f",
   "metadata": {},
   "source": [
    "## Is unnecessarily long for a natural human interaction\n",
    "While I found the response useful, it was excessively lengthy, especially considering the computational energy LLMs consume. I often have the sense that they favor __exhaustiveness__ over the brevity we often value in human conversation, because talking is energy-consuming.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67050ba-4d16-4b8e-aea8-55bc31699a63",
   "metadata": {},
   "source": [
    "## But here are the __things I truly appreciated__:\n",
    "\n",
    "1. *It provided a ready-to-use ranked list. The LLM correctly parsed the prompt's explicit instructions (\"rank your preferences\") and structured its primary output to meet that specific need.*\n",
    "   \n",
    "2. *It provided rationales connecting to my past work, which allowed me to critically evaluate the rationales and re-weigh my current prioritization.*\n",
    "\n",
    "   \n",
    "3. *It suggested practical applications. The ideas for incorporating the book's content into my other projects were genuinely insightful.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b31f2-335a-44e0-8067-1600209267c3",
   "metadata": {},
   "source": [
    "Interestingly, this final point highlights a key difference between human and AI communication. It's difficult to imagine a human expert spontaneously generating such a detailed list of potential operational connections of each book with my past experience in a casual conversation. The tips for class would also be cognitively exausive to provide. While the __cognitive load__ requried for these content would be too high for a human talker, they are easy-peasy for a LLM. \n",
    "\n",
    "## Different mental manipulation mechanisms\n",
    "So, although the tones and expressions look humane, GPT's very ability to perform this __low-cost, high-output analysis in a causal converstion__ is actually inhuman, or unatural. It doesn't rely on the same __mental shortcuts__ as human do. To him, generating these chunks of tasks have no different from the other chunks, computationally. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
